{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction"
      ],
      "metadata": {
        "id": "FcBaOIqX6maN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDL0gzCP4AfS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHCcFWGt6Sap",
        "outputId": "9980be6e-27b3-483a-c729-02297092fa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Sales Forecast/train_processed1.csv'\n",
        "train = pd.read_csv(train_path, parse_dates=['Date'])"
      ],
      "metadata": {
        "id": "UujLS4JM6UiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Datetime-Based Features"
      ],
      "metadata": {
        "id": "xDhw12Zz6pVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['Year'] = train['Date'].dt.year\n",
        "train['Month'] = train['Date'].dt.month\n",
        "train['Day'] = train['Date'].dt.day\n",
        "train['DayOfYear'] = train['Date'].dt.dayofyear\n",
        "train['WeekOfYear'] = train['Date'].dt.isocalendar().week.astype(int)\n",
        "train['IsWeekend'] = (train['DayOfWeek'] >= 6).astype(int)\n",
        "train['Quarter'] = train['Date'].dt.quarter\n",
        "train['IsMonthStart'] = train['Date'].dt.is_month_start.astype(int)\n",
        "train['IsMonthEnd'] = train['Date'].dt.is_month_end.astype(int)"
      ],
      "metadata": {
        "id": "CfRTU4be6iWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Competition and Promo Duration Features"
      ],
      "metadata": {
        "id": "gLLnrmKM_OOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['CompetitionOpenSince'] = (\n",
        "    12 * (train['Year'] - train['CompetitionOpenSinceYear']) +\n",
        "    (train['Month'] - train['CompetitionOpenSinceMonth'])\n",
        ").clip(lower=0)"
      ],
      "metadata": {
        "id": "Ft2idZhK6q6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Promo2Since'] = (\n",
        "    52 * (train['Year'] - train['Promo2SinceYear']) +\n",
        "    (train['WeekOfYear'] - train['Promo2SinceWeek'])\n",
        ").clip(lower=0)"
      ],
      "metadata": {
        "id": "Jtku7O21_YHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['IsPromo2Month'] = 0\n",
        "promo_month_map = {\n",
        "    1: [1, 4, 7, 10],   # Jan, Apr, Jul, Oct\n",
        "    2: [2, 5, 8, 11],   # Feb, May, Aug, Nov\n",
        "    3: [3, 6, 9, 12]    # Mar, Jun, Sept, Dec\n",
        "}\n",
        "\n",
        "for interval_code, months in promo_month_map.items():\n",
        "    train.loc[\n",
        "        (train['PromoInterval'] == interval_code) & (train['Month'].isin(months)),\n",
        "        'IsPromo2Month'\n",
        "    ] = 1"
      ],
      "metadata": {
        "id": "VwxPco2e_ZbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Store-level Ridge Trend Features"
      ],
      "metadata": {
        "id": "A0I2akntIU_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trend_df = []\n",
        "for store, group in train.groupby('Store'):\n",
        "    X = group[['DateInt']]\n",
        "    y = group['Sales']2\n",
        "    if len(X) >= 30:\n",
        "        model = Ridge()\n",
        "        model.fit(X, y)\n",
        "        slope = model.coef_[0]\n",
        "    else:\n",
        "        slope = 0\n",
        "    trend_df.append((store, slope))\n",
        "\n",
        "store_trends = pd.DataFrame(trend_df, columns=['Store', 'StoreTrend'])\n",
        "train = train.merge(store_trends, on='Store', how='left')"
      ],
      "metadata": {
        "id": "X4ex2ld_IYS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lag and Rolling Features"
      ],
      "metadata": {
        "id": "V8sGX5O-_kde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train = train.sort_values(['Store', 'Date'])\n",
        "\n",
        "# for lag in [1, 7, 14]:\n",
        "#     train[f'Sales_lag_{lag}'] = train.groupby('Store')['Sales'].shift(lag)\n",
        "\n",
        "# for window in [7, 14]:\n",
        "#     train[f'Sales_roll_mean_{window}'] = train.groupby('Store')['Sales'].shift(1).rolling(window).mean().reset_index(level=0, drop=True)\n",
        "#     train[f'Sales_roll_std_{window}'] = train.groupby('Store')['Sales'].shift(1).rolling(window).std().reset_index(level=0, drop=True)\n",
        "\n",
        "train = train.sort_values(['Store', 'Date'])\n",
        "for lag in [1, 7, 14, 30]:\n",
        "    train[f'Sales_lag_{lag}'] = train.groupby('Store')['Sales'].shift(lag)\n",
        "\n",
        "train['Sales_roll_mean_7'] = train.groupby('Store')['Sales'].shift(1).rolling(window=7).mean().reset_index(0, drop=True)\n",
        "train['Sales_roll_std_7'] = train.groupby('Store')['Sales'].shift(1).rolling(window=7).std().reset_index(0, drop=True)\n"
      ],
      "metadata": {
        "id": "y8Raakk-_bPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decomposition Features by StoreType (Seasonal-Trend)"
      ],
      "metadata": {
        "id": "yw8emKWm_rm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decomposed = []\n",
        "for stype in train['StoreType'].unique():\n",
        "    df = train[train['StoreType'] == stype].copy()\n",
        "    ts = df.set_index('Date').resample('D')['Sales'].mean().fillna(method='ffill')\n",
        "    if len(ts) < 60:\n",
        "        continue\n",
        "    result = seasonal_decompose(ts, model='additive', period=7)\n",
        "    tmp = pd.DataFrame({\n",
        "        'Date': result.trend.index,\n",
        "        f'StoreType_{stype}_trend': result.trend.values,\n",
        "        f'StoreType_{stype}_seasonal': result.seasonal.values,\n",
        "        f'StoreType_{stype}_resid': result.resid.values\n",
        "    })\n",
        "    decomposed.append(tmp)\n",
        "\n",
        "decomposed_df = decomposed[0]\n",
        "for d in decomposed[1:]:\n",
        "    decomposed_df = pd.merge(decomposed_df, d, on='Date', how='outer')\n",
        "\n",
        "train = pd.merge(train, decomposed_df, on='Date', how='left')"
      ],
      "metadata": {
        "id": "5B4DiW7s_naH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5107fa67-bc44-4ed6-d22e-8e7d10a72740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-51-235185249.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  ts = df.set_index('Date').resample('D')['Sales'].mean().fillna(method='ffill')\n",
            "/tmp/ipython-input-51-235185249.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  ts = df.set_index('Date').resample('D')['Sales'].mean().fillna(method='ffill')\n",
            "/tmp/ipython-input-51-235185249.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  ts = df.set_index('Date').resample('D')['Sales'].mean().fillna(method='ffill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decomposition Features by Assortment (Seasonal-Trend)"
      ],
      "metadata": {
        "id": "1VljzmEnIv6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decomposed_assort = []\n",
        "for a_type in train['Assortment'].unique():\n",
        "    df = train[train['Assortment'] == a_type].copy()\n",
        "    ts = df.set_index('Date').resample('D')['Sales'].mean().fillna(method='ffill')\n",
        "    if len(ts) < 60:\n",
        "        continue\n",
        "    result = seasonal_decompose(ts, model='additive', period=7)\n",
        "    tmp = pd.DataFrame({\n",
        "        'Date': result.trend.index,\n",
        "        f'Assortment_{a_type}_trend': result.trend.values,\n",
        "        f'Assortment_{a_type}_seasonal': result.seasonal.values,\n",
        "        f'Assortment_{a_type}_resid': result.resid.values\n",
        "    })\n",
        "    decomposed_assort.append(tmp)\n",
        "\n",
        "decomposed_df_assort = decomposed_assort[0]\n",
        "for d in decomposed_assort[1:]:\n",
        "    decomposed_df_assort = pd.merge(decomposed_df_assort, d, on='Date', how='outer')\n",
        "\n",
        "train = pd.merge(train, decomposed_df_assort, on='Date', how='left')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DKGTz9eIydM",
        "outputId": "557cf19b-98d0-4846-b4cd-15cb03a02350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-52-2714935869.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  ts = df.set_index('Date').resample('D')['Sales'].mean().fillna(method='ffill')\n",
            "/tmp/ipython-input-52-2714935869.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  ts = df.set_index('Date').resample('D')['Sales'].mean().fillna(method='ffill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiwaNvcU_wv0",
        "outputId": "e6380187-f44a-4eec-f38e-49c1425195b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Store',\n",
              " 'DayOfWeek',\n",
              " 'Date',\n",
              " 'Sales',\n",
              " 'Open',\n",
              " 'Promo',\n",
              " 'StateHoliday',\n",
              " 'SchoolHoliday',\n",
              " 'StoreType',\n",
              " 'Assortment',\n",
              " 'CompetitionDistance',\n",
              " 'CompetitionOpenSinceMonth',\n",
              " 'CompetitionOpenSinceYear',\n",
              " 'Promo2',\n",
              " 'Promo2SinceWeek',\n",
              " 'Promo2SinceYear',\n",
              " 'PromoInterval',\n",
              " 'DateInt',\n",
              " 'Year',\n",
              " 'Month',\n",
              " 'Day',\n",
              " 'DayOfYear',\n",
              " 'WeekOfYear',\n",
              " 'IsWeekend',\n",
              " 'Quarter',\n",
              " 'IsMonthStart',\n",
              " 'IsMonthEnd',\n",
              " 'CompetitionOpenSince',\n",
              " 'Promo2Since',\n",
              " 'IsPromo2Month',\n",
              " 'StoreTrend',\n",
              " 'Sales_lag_1',\n",
              " 'Sales_lag_7',\n",
              " 'Sales_lag_14',\n",
              " 'Sales_lag_30',\n",
              " 'Sales_roll_mean_7',\n",
              " 'Sales_roll_std_7',\n",
              " 'StoreType_2_trend',\n",
              " 'StoreType_2_seasonal',\n",
              " 'StoreType_2_resid',\n",
              " 'StoreType_0_trend',\n",
              " 'StoreType_0_seasonal',\n",
              " 'StoreType_0_resid',\n",
              " 'StoreType_3_trend',\n",
              " 'StoreType_3_seasonal',\n",
              " 'StoreType_3_resid',\n",
              " 'StoreType_1_trend',\n",
              " 'StoreType_1_seasonal',\n",
              " 'StoreType_1_resid',\n",
              " 'Assortment_0_trend',\n",
              " 'Assortment_0_seasonal',\n",
              " 'Assortment_0_resid',\n",
              " 'Assortment_2_trend',\n",
              " 'Assortment_2_seasonal',\n",
              " 'Assortment_2_resid',\n",
              " 'Assortment_1_trend',\n",
              " 'Assortment_1_seasonal',\n",
              " 'Assortment_1_resid']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These days have no sales and do not help the model learn useful patterns.\n"
      ],
      "metadata": {
        "id": "1m_dg6b-Ape7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[(train['Open'] == 1) & (train['Sales'] > 0)]"
      ],
      "metadata": {
        "id": "Ii8tw-M_AnGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArtPW1-nAySR",
        "outputId": "2fbc18de-d57e-46f7-e1f1-7f42a1efa02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(844338, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('/content/drive/MyDrive/Sales Forecast/train_final1.csv', index=False)"
      ],
      "metadata": {
        "id": "AxWn7c5SA3_M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}